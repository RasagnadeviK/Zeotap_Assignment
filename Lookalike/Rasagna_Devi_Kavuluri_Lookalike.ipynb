{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCHps8oV5Jr_",
        "outputId": "4a9b32e1-0d6c-4579-add3-fce60f97fca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-9d032a11e622>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  customer_features[pid] = customer_features['ProductID'].apply(lambda x: 1 if pid in x else 0)\n",
            "<ipython-input-23-9d032a11e622>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  customer_features[pid] = customer_features['ProductID'].apply(lambda x: 1 if pid in x else 0)\n",
            "<ipython-input-23-9d032a11e622>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  customer_features[pid] = customer_features['ProductID'].apply(lambda x: 1 if pid in x else 0)\n",
            "<ipython-input-23-9d032a11e622>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  customer_features[pid] = customer_features['ProductID'].apply(lambda x: 1 if pid in x else 0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Load the datasets\n",
        "customer_data = pd.read_csv('Customers.csv')\n",
        "product_data = pd.read_csv('Products.csv')\n",
        "transaction_data = pd.read_csv('Transactions.csv')\n",
        "# Merge the datasets to get a comprehensive dataset\n",
        "data = transactions.merge(customers, on='CustomerID').merge(products, on='ProductID')\n",
        "# Task 2: Lookalike Model\n",
        "# Preparing customer features\n",
        "customer_features = data.groupby('CustomerID').agg({\n",
        "    'Region': 'first',\n",
        "    'ProductID': lambda x: list(x),\n",
        "    'TotalValue': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "customer_features['Region'] = label_encoder.fit_transform(customer_features['Region'])\n",
        "\n",
        "# Create binary columns for ProductID\n",
        "unique_product_ids = sorted(data['ProductID'].unique())\n",
        "for pid in unique_product_ids:\n",
        "    customer_features[pid] = customer_features['ProductID'].apply(lambda x: 1 if pid in x else 0)\n",
        "customer_features.drop('ProductID', axis=1, inplace=True)\n",
        "\n",
        "# Compute similarity scores\n",
        "feature_matrix = customer_features.iloc[:, 1:].values\n",
        "similarity_matrix = cosine_similarity(feature_matrix)\n",
        "\n",
        "# Generate top 3 lookalike customers for the first 20 customers\n",
        "lookalike_results = {}\n",
        "for i, customer_id in enumerate(customer_features['CustomerID'][:20]):\n",
        "    similarity_scores = list(enumerate(similarity_matrix[i]))\n",
        "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)[1:4]\n",
        "    lookalike_results[customer_id] = [(customer_features['CustomerID'][j], round(score, 2)) for j, score in similarity_scores]\n",
        "\n",
        "# Save results to CSV\n",
        "lookalike_df = pd.DataFrame({\n",
        "    'CustomerID': list(lookalike_results.keys()),\n",
        "    'Lookalikes': [str(v) for v in lookalike_results.values()]\n",
        "})\n",
        "lookalike_df.to_csv('Rasagna_Devi_Kavuluri_Lookalike.csv', index=False)"
      ]
    }
  ]
}